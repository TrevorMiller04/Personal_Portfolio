[
  {
    "title": "Interactive Portfolio Website",
    "date": "2025-08",
    "description": "Production-ready academic portfolio website with modern Next.js architecture, full-stack database integration, and AI-powered contact form",
    "tech": ["Next.js", "React", "TypeScript", "Tailwind CSS", "Prisma", "Supabase", "Vercel", "Resend", "Zod"],
    "repoURL": "https://github.com/TrevorMiller04/Personal_Portfolio",
    "liveUrl": "https://trevormiller.xyz",
    "longDescription": "<p>Built a production-ready academic portfolio website using <strong>Next.js App Router</strong>, <strong>React 19</strong>, and <strong>TypeScript strict mode</strong>, structuring the application for recruiter-facing clarity, performance, and long-term maintainability.</p><p><strong>Key Features:</strong></p><ul><li>Full-stack architecture integrating PostgreSQL database via <strong>Supabase</strong> and <strong>Prisma ORM</strong> to manage real project data and contact submissions with strongly typed models</li><li>Contact form pipeline that persists submissions to database, triggers transactional email notifications via <strong>Resend</strong>, and generates context-aware AI responses using deterministic logic</li><li>API routes with <strong>Zod-based request validation</strong> to enforce schema correctness across frontend–backend boundaries</li><li>CI/CD pipeline using <strong>GitHub Actions</strong> to automate linting, type checking, and build verification</li><li>Performance optimization with explicit bundle size awareness and frontend rendering efficiency targets</li></ul><p><strong>Technical Implementation:</strong></p><ul><li>Syracuse University branding with custom design system using Tailwind CSS</li><li>Deployed to <strong>Vercel</strong> with environment-based configuration and production build optimization</li><li>Constrained AI integration focused on augmenting user communication without generating fabricated information</li><li>Strict authenticity policy: only verifiable academic work and real implementations showcased</li></ul>",
    "images": [
      { "src": "/projects/portfolio/portfolio_project1.png", "alt": "Portfolio homepage with Syracuse University branding", "caption": "Homepage featuring responsive design and campus background" },
      { "src": "/projects/portfolio/portfolio_project2.png", "alt": "Technical workflow diagram", "caption": "Full-stack architecture and deployment workflow" }
    ]
  },
  {
    "title": "Multitext Classification Model",
    "date": "2025-09",
    "description": "End-to-end NLP classification system using transformer architecture, deployed as AWS SageMaker endpoint with serverless API integration",
    "tech": ["PyTorch", "DistilBERT", "AWS SageMaker", "AWS Lambda", "API Gateway", "Python", "Postman"],
    "longDescription": "<p>Completed an end-to-end applied machine learning project focused on building, customizing, deploying, and productionizing an <strong>NLP-based multiclass text classification system</strong> using modern transformer architectures.</p><p><strong>Model Development:</strong></p><ul><li>Implemented transformer-based classification pipeline by extending pre-trained <strong>DistilBERT</strong> with custom PyTorch layers (dropout, linear, ReLU) for sequence-level classification using CLS token representations</li><li>Applied mathematical foundations of transformers: positional encodings, query–key–value attention, softmax normalization, and multi-head attention</li><li>Built custom PyTorch training, validation, and accuracy evaluation loops with optimizer configuration and cross-entropy loss computation</li><li>Designed complete SageMaker training configuration and parameter pipeline</li></ul><p><strong>Production Deployment:</strong></p><ul><li>Developed custom inference script to load trained model, process tokenized inputs, and return structured predictions from <strong>SageMaker-managed endpoint</strong></li><li>Conducted endpoint load testing using <strong>SageMaker Inference Recommender</strong> to analyze latency, throughput, and instance sizing tradeoffs</li><li>Productionized the system by integrating <strong>AWS Lambda</strong> and <strong>API Gateway</strong> to expose inference endpoint via HTTP API</li><li>Validated end-to-end inference using <strong>Postman</strong> with proper IAM role configuration</li></ul>",
    "images": [
      { "src": "/projects/multitext-classification/postman-response.png", "alt": "Postman API response showing model predictions with health probabilities", "caption": "Successful inference request with health classification probabilities (200 OK)" },
      { "src": "/projects/multitext-classification/lambda-architecture.png", "alt": "AWS Lambda function architecture diagram", "caption": "Production deployment architecture with API Gateway and Lambda integration" }
    ]
  },
  {
    "title": "Spotify Playlist Generator",
    "date": "2025-06",
    "description": "Python data pipeline transforming 95,000+ Spotify listening records into year-specific playlists via automated API integration",
    "tech": ["Python", "Pandas", "Spotify Web API", "Spotipy", "JSON", "Excel", "OAuth"],
    "longDescription": "<p>Built a Python-based data pipeline that transforms raw Spotify personal listening history into structured datasets and automatically generates year-specific playlists using the <strong>Spotify Web API</strong>.</p><p><strong>Data Processing Pipeline:</strong></p><ul><li>Implemented Python data ingestion pipeline that parsed and flattened Spotify streaming history JSON files spanning <strong>2017–2025</strong>, processing <strong>95,572 playback records</strong> into structured Pandas DataFrames</li><li>Cleaned and normalized raw playback metadata by converting millisecond timestamps to human-readable formats, filtering skipped plays, and standardizing track/artist fields</li><li>Aggregated listening behavior at track and artist level: total minutes listened, play counts, first/last play timestamps</li><li>Designed configurable filtering logic based on listening time thresholds and play count thresholds for multiple playlist strategies</li></ul><p><strong>API Integration & Automation:</strong></p><ul><li>Automated creation of year-specific Spotify playlists, producing collections ranging from <strong>dozens to 700+ tracks</strong> depending on listening volume</li><li>Integrated with Spotify Web API using <strong>OAuth authentication</strong> and programmatic search to resolve track identifiers</li><li>Implemented batched API operations (up to 100 tracks per request) with controlled delays to reduce rate-limit risk</li><li>Structured project into modular scripts separating data ingestion, refinement, and API interaction</li></ul>",
    "images": [
      { "src": "/projects/spotify-generator/playlist-view.png", "alt": "Spotify playlists created from 2017-2025 listening history", "caption": "Year-specific playlists generated from 95,000+ playback records (2017-2025)" }
    ]
  },
  {
    "title": "Spur Mobile Application",
    "date": "2025-05",
    "description": "React Native mobile app enabling spontaneous social planning with AI-powered activity suggestions and location-based features",
    "tech": ["React Native", "Expo", "TypeScript", "OpenAI API", "Node.js", "Express", "PostgreSQL", "Jira"],
    "longDescription": "<p>One-semester mobile application built in a Software Implementation course using <strong>Agile/Scrum workflow</strong> with <strong>1-week sprints</strong>. The app focused on enabling spontaneous, short-notice social plans through friend discovery, availability tracking, time-matching, and AI-powered activity suggestions.</p><p><strong>Frontend Development:</strong></p><ul><li>Built mobile UI flows in <strong>React Native/Expo</strong> for key scheduling features: event creation steps, availability input, and navigation coherence across multi-screen flows</li><li>Implemented location-aware UX capabilities: <strong>GPS/manual location input</strong> and location-based activity filtering to tailor suggestions based on user preferences</li><li>Delivered social coordination features including friend request logic for matches and cohesive navigation between core features (match, schedule, explore, profile)</li></ul><p><strong>AI Integration (Applied AI Focus):</strong></p><ul><li>Implemented AI activity suggestions feature by integrating <strong>OpenAI API</strong>, designing prompts that produced <strong>structured JSON</strong> outputs usable by the client</li><li>Added guardrails around AI generation: validation, fallback handling, and error resilience to ensure usable experience even with incomplete/malformed responses</li><li>Implemented <strong>caching</strong> for AI suggestions to reduce repeated calls, improving responsiveness and managing API usage/cost tradeoffs</li></ul><p><strong>Team Collaboration:</strong></p><ul><li>Served as <strong>Scrum Master (2 rotations)</strong> in 4-person team, facilitating sprint ceremonies and coordinating with professor acting as Product Owner</li><li>Created <strong>Jira automation agents/commands</strong> to standardize story intake, updates, test planning, and archival—enforcing consistent execution</li><li>Completed <strong>13 Done stories</strong> with <strong>73.5+ hours logged</strong> across features spanning UI, AI integration, and developer productivity tooling</li></ul>",
    "images": []
  }
]
